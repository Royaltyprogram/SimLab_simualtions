{
	"componentName": "CartPole",
	"contributorGithub": "Royaltyprogram",
	"contributorImage": "https://avatars.githubusercontent.com/u/165759805?v=4&size=64",
	"createdAt": 20241209,
	"description": "# Detailed Description of the CartPole Experiment\n\nThe CartPole problem is a classical control problem frequently studied in reinforcement learning. It involves balancing a pole (Pole) on a movable cart (Cart) to keep the pole upright. This experiment models a physical system and solves it using equations of motion combined with reinforcement learning algorithms. The goal is to control the force applied to the cart to maintain the pole in an upright position.\n\n---\n\n## Physical Model\n\nThe physical model of the CartPole system is based on Newton's laws of motion and rotational dynamics, described by the following equations of motion:\n\n### 1. Definition of Variables\n- \\( x \\): Horizontal position of the cart\n- \\( \\dot{x} \\): Horizontal velocity of the cart\n- \\( \\theta \\): Angle of the pole (deviation from vertical)\n- \\( \\dot{\\theta} \\): Angular velocity of the pole\n\n### 2. Physical Constants\n- \\( g \\): Gravitational acceleration (\\( g = 9.8 \\, \\text{m/s}^2 \\))\n- \\( m_c \\): Mass of the cart\n- \\( m_p \\): Mass of the pole\n- \\( l \\): Length of the pole\n- \\( F \\): External force applied to the cart\n\n### 3. Equations of Motion\nThe dynamics of the CartPole system are represented by nonlinear equations of motion. A simplified 2D model is described as follows:\n\n- **Acceleration of the cart**:\n  \\[\n  \\ddot{x} = \\frac{F + m_p \\cdot l \\cdot (\\dot{\\theta}^2 \\cdot \\sin\\theta - \\ddot{\\theta} \\cdot \\cos\\theta)}{m_c + m_p}\n  \\]\n\n- **Angular acceleration of the pole**:\n  \\[\n  \\ddot{\\theta} = \\frac{g \\cdot \\sin\\theta - \\cos\\theta \\cdot \\frac{F + m_p \\cdot l \\cdot \\dot{\\theta}^2 \\cdot \\sin\\theta}{m_c + m_p}}{l \\cdot \\left(\\frac{4}{3} - \\frac{m_p \\cdot \\cos^2\\theta}{m_c + m_p}\\right)}\n  \\]\n\nHere, \\( \\sin\\theta \\) and \\( \\cos\\theta \\) represent the trigonometric relationships based on the angle \\( \\theta \\).\n\n---\n\n## Application of Reinforcement Learning\n\nThe CartPole problem is modeled using three components in reinforcement learning: State, Action, and Reward.\n\n### 1. State Space\nThe state consists of dynamic variables of the system:\n\\[\ns = (x, \\dot{x}, \\theta, \\dot{\\theta})\n\\]\nThis state space is continuous but is discretized for algorithms like Q-learning.\n\n### 2. Action Space\nThe action space represents the direction of the force applied to the cart:\n\\[\na \\in \\{\\text{Left Force}, \\text{Right Force}\\}\n\\]\n\n### 3. Reward Function\nThe system receives a reward of \\( +1 \\) for maintaining the pole upright. If the pole's angle exceeds \\( |\\theta| > \\theta_{\\text{max}} \\) or the cart's position exceeds \\( |x| > x_{\\text{max}} \\), the episode terminates, and a reward of \\( 0 \\) is assigned.\n\n### 4. Objective\nThe objective is to maximize the average episodic reward, effectively increasing the time the pole remains upright.\n\n---\n\n## Algorithms\n\nThe CartPole problem can be solved using various reinforcement learning algorithms, including Q-learning and Deep Q-Networks (DQN).\n\n- **Q-learning**:\n  The state-action value function \\( Q(s, a) \\) is updated to learn the optimal policy \\( \\pi(s) \\):\n  \\[\n  Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\cdot \\max_{a'} Q(s', a') - Q(s, a) \\right)\n  \\]\n  Here, \\( \\alpha \\) is the learning rate, \\( \\gamma \\) is the discount factor, and \\( r \\) is the current reward.\n\n- **Deep Reinforcement Learning (DQN)**:\n  In high-dimensional state spaces, neural networks approximate the \\( Q \\)-function, enabling efficient learning even in continuous state spaces.\n\n---\n\n## Conclusion\n\nThe CartPole problem is widely used to evaluate the performance of reinforcement learning algorithms. It can be solved using simple Q-learning or advanced methods like DQN. This experiment demonstrates the integration of physical modeling, reinforcement learning, and control theory to test AI's capability to solve control problems effectively.",
	"githubRepo": "Royaltyprogram/SimLab",
	"likes": 0,
	"name": "Q-Learning CartPole Simulation",
	"simulationFilename": "CartPole",
	"thumbnailPath": "https://firebasestorage.googleapis.com/v0/b/simlab-3a966.firebasestorage.app/o/thumbnails%2FCartPole.png?alt=media&token=e4b71148-11c7-49b6-82c2-3f6b7c5c414d",
	"updatedAt": 20241209,
	"views": 0
  }